{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Seedling - ResNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/py35/lib/python3.5/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import os\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras import optimizers\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D, BatchNormalization\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.applications import *\n",
    "from keras.applications.resnet50 import preprocess_input\n",
    "from sklearn.model_selection import StratifiedShuffleSplit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numbers of sharpTrainImage images 4750\n",
      "Numbers of sharpTestImage images 794\n",
      "Numbers of train labels 4750\n"
     ]
    }
   ],
   "source": [
    "sharpTrainImage = np.load(os.path.join(os.getcwd(),'Image224/sharpTrainImage.npy'))\n",
    "sharpTestImage = np.load(os.path.join(os.getcwd(),'Image224/sharpTestImage.npy'))\n",
    "trainLabels = np.load(os.path.join(os.getcwd(),'Image224/trainLabels.npy'))\n",
    "\n",
    "print(\"Numbers of sharpTrainImage images\", len(sharpTrainImage))\n",
    "print(\"Numbers of sharpTestImage images\", len(sharpTestImage))\n",
    "print(\"Numbers of train labels\", len(trainLabels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(224, 224, 3)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sharpTrainImage[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one - hot coding\n",
    "trainLabels = to_categorical(trainLabels, 12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4750, 12)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainLabels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 3990 for training and 760 for validation\n"
     ]
    }
   ],
   "source": [
    "#x_train, x_valid, y_train, y_valid = train_test_split(x_train, y_train, test_size=0.01, random_state=42)\n",
    "\n",
    "sss = StratifiedShuffleSplit(n_splits=1, test_size=0.16, random_state=42) # Want a balanced split for all the classes\n",
    "\n",
    "for train_index, test_index in sss.split(sharpTrainImage, trainLabels):\n",
    "    print(\"Using {} for training and {} for validation\".format(len(train_index), len(test_index)))\n",
    "    x_train, x_valid = sharpTrainImage[train_index], sharpTrainImage[test_index]\n",
    "    y_train, y_valid = trainLabels[train_index], trainLabels[test_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(\n",
    "                            preprocessing_function = preprocess_input,\n",
    "                            rotation_range=180,\n",
    "                            width_shift_range=0.3,\n",
    "                            height_shift_range=0.3,\n",
    "                            zoom_range=0.3,\n",
    "                            horizontal_flip=True, \n",
    "                            vertical_flip=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 50\n",
    "learning_rate = 0.0001\n",
    "batch_size = 32\n",
    "dim = 224\n",
    "\n",
    "weights = os.path.join('', 'weights.h5')\n",
    "\n",
    "callbacks = [ EarlyStopping(monitor='val_loss', patience=5, verbose=0), \n",
    "              ModelCheckpoint(weights, monitor='val_loss', save_best_only=True, verbose=0),\n",
    "              ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=2, verbose=0, mode='auto', epsilon=0.0001, cooldown=0, min_lr=0)]\n",
    "\n",
    "base_model = ResNet50(input_shape=(dim, dim, 3), include_top=False, weights='imagenet', pooling='avg') \n",
    "# Average pooling reduces output dimensions\n",
    "x = base_model.output\n",
    "x = Dense(dim, activation='relu')(x)\n",
    "x = Dropout(0.5)(x)\n",
    "predictions = Dense(12, activation='softmax')(x)\n",
    "\n",
    "model = Model(inputs=base_model.input, outputs=predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 50\n",
    "learning_rate = 0.0001\n",
    "batch_size = 16\n",
    "dim = 224\n",
    "\n",
    "weights = os.path.join('', 'weights.h5')\n",
    "\n",
    "callbacks = [ EarlyStopping(monitor='val_loss', patience=5, verbose=0), \n",
    "              ModelCheckpoint(weights, monitor='val_loss', save_best_only=True, verbose=0),\n",
    "              ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=2, verbose=0, mode='auto', epsilon=0.0001, cooldown=0, min_lr=0)]\n",
    "\n",
    "base_model = ResNet50(input_shape=(dim, dim, 3), include_top=False, weights='imagenet', pooling='avg') \n",
    "# Average pooling reduces output dimensions\n",
    "x = base_model.output\n",
    "x = Dense(dim, activation='relu')(x)\n",
    "x = Dropout(0.5)(x)\n",
    "predictions = Dense(12, activation='softmax')(x)\n",
    "\n",
    "model = Model(inputs=base_model.input, outputs=predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer=optimizers.Adadelta(), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "125/124 [==============================] - 140s 1s/step - loss: 1.4312 - acc: 0.5524 - val_loss: 14.0334 - val_acc: 0.1289\n",
      "Epoch 2/50\n",
      "125/124 [==============================] - 133s 1s/step - loss: 0.7985 - acc: 0.7490 - val_loss: 2.3263 - val_acc: 0.4434\n",
      "Epoch 3/50\n",
      "125/124 [==============================] - 132s 1s/step - loss: 0.5939 - acc: 0.7974 - val_loss: 0.8596 - val_acc: 0.6776\n",
      "Epoch 4/50\n",
      "125/124 [==============================] - 133s 1s/step - loss: 0.5198 - acc: 0.8312 - val_loss: 1.3475 - val_acc: 0.5711\n",
      "Epoch 5/50\n",
      "125/124 [==============================] - 133s 1s/step - loss: 0.4338 - acc: 0.8567 - val_loss: 1.3627 - val_acc: 0.5289\n",
      "Epoch 6/50\n",
      "125/124 [==============================] - 133s 1s/step - loss: 0.3871 - acc: 0.8683 - val_loss: 1.3737 - val_acc: 0.6092\n",
      "Epoch 7/50\n",
      "125/124 [==============================] - 132s 1s/step - loss: 0.2755 - acc: 0.9034 - val_loss: 0.2402 - val_acc: 0.9039\n",
      "Epoch 8/50\n",
      "125/124 [==============================] - 132s 1s/step - loss: 0.2156 - acc: 0.9202 - val_loss: 0.1920 - val_acc: 0.9289\n",
      "Epoch 9/50\n",
      "125/124 [==============================] - 133s 1s/step - loss: 0.1966 - acc: 0.9303 - val_loss: 0.2093 - val_acc: 0.9184\n",
      "Epoch 10/50\n",
      "125/124 [==============================] - 132s 1s/step - loss: 0.1922 - acc: 0.9334 - val_loss: 0.1770 - val_acc: 0.9355\n",
      "Epoch 11/50\n",
      "125/124 [==============================] - 133s 1s/step - loss: 0.1909 - acc: 0.9328 - val_loss: 0.2099 - val_acc: 0.9263\n",
      "Epoch 12/50\n",
      "125/124 [==============================] - 133s 1s/step - loss: 0.1821 - acc: 0.9327 - val_loss: 0.2134 - val_acc: 0.9197\n",
      "Epoch 13/50\n",
      "125/124 [==============================] - 132s 1s/step - loss: 0.1719 - acc: 0.9385 - val_loss: 0.2014 - val_acc: 0.9197\n",
      "Epoch 14/50\n",
      "125/124 [==============================] - 133s 1s/step - loss: 0.1786 - acc: 0.9372 - val_loss: 0.1575 - val_acc: 0.9434\n",
      "Epoch 15/50\n",
      "125/124 [==============================] - 132s 1s/step - loss: 0.1617 - acc: 0.9432 - val_loss: 0.1856 - val_acc: 0.9237\n",
      "Epoch 16/50\n",
      "125/124 [==============================] - 132s 1s/step - loss: 0.1573 - acc: 0.9451 - val_loss: 0.1662 - val_acc: 0.9355\n",
      "Epoch 17/50\n",
      "125/124 [==============================] - 133s 1s/step - loss: 0.1661 - acc: 0.9434 - val_loss: 0.1790 - val_acc: 0.9263\n",
      "Epoch 18/50\n",
      "125/124 [==============================] - 133s 1s/step - loss: 0.1665 - acc: 0.9393 - val_loss: 0.1709 - val_acc: 0.9395\n",
      "Epoch 19/50\n",
      "125/124 [==============================] - 132s 1s/step - loss: 0.1695 - acc: 0.9368 - val_loss: 0.1702 - val_acc: 0.9329\n",
      "running time:  0:42:22.513281\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "local_start = datetime.datetime.now()\n",
    "# ------ TRAINING ------\n",
    "model.fit_generator(datagen.flow(x_train, y_train, batch_size=batch_size),\n",
    "                    steps_per_epoch=len(x_train)/batch_size, \n",
    "                    validation_data=datagen.flow(x_valid, y_valid, batch_size=batch_size), \n",
    "                    validation_steps=len(x_valid)/batch_size,\n",
    "                    callbacks=callbacks,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1)\n",
    "\n",
    "print('running time: ', datetime.datetime.now()-local_start) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "297/296 [==============================] - 189s 637ms/step - loss: 1.7012 - acc: 0.4625\n",
      "Epoch 2/50\n",
      "297/296 [==============================] - 181s 610ms/step - loss: 0.9520 - acc: 0.6889\n",
      "Epoch 3/50\n",
      "297/296 [==============================] - 181s 610ms/step - loss: 0.7214 - acc: 0.7577\n",
      "Epoch 4/50\n",
      "297/296 [==============================] - 181s 609ms/step - loss: 0.6140 - acc: 0.7932\n",
      "Epoch 5/50\n",
      "297/296 [==============================] - 181s 609ms/step - loss: 0.5178 - acc: 0.8209\n",
      "Epoch 6/50\n",
      "297/296 [==============================] - 181s 609ms/step - loss: 0.4749 - acc: 0.8373\n",
      "Epoch 7/50\n",
      "297/296 [==============================] - 181s 609ms/step - loss: 0.4371 - acc: 0.8580\n",
      "Epoch 8/50\n",
      "297/296 [==============================] - 181s 610ms/step - loss: 0.3953 - acc: 0.8707\n",
      "Epoch 9/50\n",
      "297/296 [==============================] - 181s 610ms/step - loss: 0.3866 - acc: 0.8701\n",
      "Epoch 10/50\n",
      "297/296 [==============================] - 181s 609ms/step - loss: 0.3496 - acc: 0.8828\n",
      "Epoch 11/50\n",
      "297/296 [==============================] - 181s 608ms/step - loss: 0.3406 - acc: 0.8868\n",
      "Epoch 12/50\n",
      "297/296 [==============================] - 181s 609ms/step - loss: 0.3165 - acc: 0.8912\n",
      "Epoch 13/50\n",
      "297/296 [==============================] - 181s 608ms/step - loss: 0.3117 - acc: 0.8917\n",
      "Epoch 14/50\n",
      "297/296 [==============================] - 181s 609ms/step - loss: 0.3003 - acc: 0.8954\n",
      "Epoch 15/50\n",
      "297/296 [==============================] - 181s 609ms/step - loss: 0.2860 - acc: 0.9013\n",
      "Epoch 16/50\n",
      "297/296 [==============================] - 181s 609ms/step - loss: 0.2688 - acc: 0.9116\n",
      "Epoch 17/50\n",
      "297/296 [==============================] - 181s 610ms/step - loss: 0.2718 - acc: 0.9065\n",
      "Epoch 18/50\n",
      "297/296 [==============================] - 181s 610ms/step - loss: 0.2730 - acc: 0.9055\n",
      "Epoch 19/50\n",
      "297/296 [==============================] - 181s 609ms/step - loss: 0.2460 - acc: 0.9113\n",
      "Epoch 20/50\n",
      "297/296 [==============================] - 181s 609ms/step - loss: 0.2336 - acc: 0.9160\n",
      "Epoch 21/50\n",
      "297/296 [==============================] - 181s 609ms/step - loss: 0.2484 - acc: 0.9175\n",
      "Epoch 22/50\n",
      "297/296 [==============================] - 181s 609ms/step - loss: 0.2429 - acc: 0.9208\n",
      "Epoch 23/50\n",
      "297/296 [==============================] - 181s 610ms/step - loss: 0.2291 - acc: 0.9238\n",
      "Epoch 24/50\n",
      "297/296 [==============================] - 181s 609ms/step - loss: 0.2168 - acc: 0.9206\n",
      "Epoch 25/50\n",
      "297/296 [==============================] - 181s 609ms/step - loss: 0.2408 - acc: 0.9173\n",
      "Epoch 26/50\n",
      "297/296 [==============================] - 181s 610ms/step - loss: 0.2296 - acc: 0.9221\n",
      "Epoch 27/50\n",
      "297/296 [==============================] - 181s 608ms/step - loss: 0.2092 - acc: 0.9326\n",
      "Epoch 28/50\n",
      "297/296 [==============================] - 181s 609ms/step - loss: 0.2048 - acc: 0.9234\n",
      "Epoch 29/50\n",
      "297/296 [==============================] - 181s 609ms/step - loss: 0.2348 - acc: 0.9175\n",
      "Epoch 30/50\n",
      "297/296 [==============================] - 181s 610ms/step - loss: 0.2119 - acc: 0.9251\n",
      "Epoch 31/50\n",
      "297/296 [==============================] - 181s 609ms/step - loss: 0.2100 - acc: 0.9278\n",
      "Epoch 32/50\n",
      "297/296 [==============================] - 181s 608ms/step - loss: 0.1919 - acc: 0.9339\n",
      "Epoch 33/50\n",
      "297/296 [==============================] - 181s 609ms/step - loss: 0.1846 - acc: 0.9328\n",
      "Epoch 34/50\n",
      "297/296 [==============================] - 181s 609ms/step - loss: 0.2169 - acc: 0.9229\n",
      "Epoch 35/50\n",
      "297/296 [==============================] - 181s 610ms/step - loss: 0.2106 - acc: 0.9308\n",
      "Epoch 36/50\n",
      "297/296 [==============================] - 181s 609ms/step - loss: 0.1855 - acc: 0.9352\n",
      "Epoch 37/50\n",
      "297/296 [==============================] - 181s 609ms/step - loss: 0.1867 - acc: 0.9339\n",
      "Epoch 38/50\n",
      "297/296 [==============================] - 181s 609ms/step - loss: 0.1902 - acc: 0.9345\n",
      "Epoch 39/50\n",
      "297/296 [==============================] - 181s 610ms/step - loss: 0.1804 - acc: 0.9362\n",
      "Epoch 40/50\n",
      "297/296 [==============================] - 181s 609ms/step - loss: 0.1832 - acc: 0.9387\n",
      "Epoch 41/50\n",
      "297/296 [==============================] - 181s 609ms/step - loss: 0.1844 - acc: 0.9364\n",
      "Epoch 42/50\n",
      "297/296 [==============================] - 181s 609ms/step - loss: 0.1776 - acc: 0.9394\n",
      "Epoch 43/50\n",
      "297/296 [==============================] - 181s 611ms/step - loss: 0.1708 - acc: 0.9419\n",
      "Epoch 44/50\n",
      "297/296 [==============================] - 181s 610ms/step - loss: 0.1828 - acc: 0.9385\n",
      "Epoch 45/50\n",
      "297/296 [==============================] - 181s 610ms/step - loss: 0.1740 - acc: 0.9444\n",
      "Epoch 46/50\n",
      "297/296 [==============================] - 181s 609ms/step - loss: 0.1608 - acc: 0.9444\n",
      "Epoch 47/50\n",
      "297/296 [==============================] - 181s 610ms/step - loss: 0.1794 - acc: 0.9380\n",
      "Epoch 48/50\n",
      "297/296 [==============================] - 181s 609ms/step - loss: 0.1704 - acc: 0.9398\n",
      "Epoch 49/50\n",
      "297/296 [==============================] - 181s 609ms/step - loss: 0.1813 - acc: 0.9407\n",
      "Epoch 50/50\n",
      "297/296 [==============================] - 181s 609ms/step - loss: 0.1655 - acc: 0.9434\n",
      "running time:  2:31:02.889829\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "local_start = datetime.datetime.now()\n",
    "# ------ TRAINING ------\n",
    "model.fit_generator(datagen.flow(sharpTrainImage, trainLabels, batch_size=batch_size),\n",
    "                    steps_per_epoch=len(sharpTrainImage)/batch_size, \n",
    "                    epochs=epochs,\n",
    "                    verbose=1)\n",
    "\n",
    "print('running time: ', datetime.datetime.now()-local_start) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('model_resnet50_Adadelta_NoValidation.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_n2s(x):\n",
    "    return {\n",
    "        0: 'Black-grass',\n",
    "        1: 'Charlock',\n",
    "        2: 'Cleavers',\n",
    "        3: 'Common Chickweed',\n",
    "        4: 'Common wheat', \n",
    "        5: 'Fat Hen',\n",
    "        6: 'Loose Silky-bent',\n",
    "        7: 'Maize',\n",
    "        8: 'Scentless Mayweed',\n",
    "        9: 'Shepherds Purse',\n",
    "        10: 'Small-flowered Cranesbill',\n",
    "        11: 'Sugar beet'\n",
    "    }.get(x, 'None')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Peocess: 0\n"
     ]
    }
   ],
   "source": [
    "predLabel = []\n",
    "for i in range(len(sharpTestImage)):\n",
    "    images = datagen.flow(np.expand_dims(sharpTestImage[i],axis=0))\n",
    "    pred = np.zeros((1,12))\n",
    "    for j,img in enumerate(images):\n",
    "        pred += model.predict(img)\n",
    "        if j > 100:\n",
    "            break\n",
    "    label = np.argmax(pred)\n",
    "    predLabel.append(label_n2s(label))\n",
    "    if (i%100==0):\n",
    "        print(\"Peocess:\",i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "794"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(predLabel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_csv('sample_submission.csv')\n",
    "testName = np.load(os.path.join(os.getcwd(),'Image/testName.npy'))\n",
    "df_test['file'] = testName\n",
    "df_test['species'] = predLabel\n",
    "df_test.to_csv('submission_resnet50.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 Spark - local",
   "language": "python",
   "name": "spark-3-python"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
