{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from glob import glob\n",
    "import cv2\n",
    "import math\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Covert ClassName to Integer method\n",
    "def label_s2n(x):\n",
    "    return {\n",
    "        'Black-grass': 0,\n",
    "        'Charlock': 1,\n",
    "        'Cleavers': 2,\n",
    "        'Common Chickweed': 3,\n",
    "        'Common wheat': 4, \n",
    "        'Fat Hen': 5,\n",
    "        'Loose Silky-bent': 6,\n",
    "        'Maize': 7,\n",
    "        'Scentless Mayweed': 8,\n",
    "        'Shepherds Purse': 9,\n",
    "        'Small-flowered Cranesbill': 10,\n",
    "        'Sugar beet': 11\n",
    "    }.get(x, 12)\n",
    "\n",
    "def label_n2s(x):\n",
    "    return {\n",
    "        0: 'Black-grass',\n",
    "        1: 'Charlock',\n",
    "        2: 'Cleavers',\n",
    "        3: 'Common Chickweed',\n",
    "        4: 'Common wheat', \n",
    "        5: 'Fat Hen',\n",
    "        6: 'Loose Silky-bent',\n",
    "        7: 'Maize',\n",
    "        8: 'Scentless Mayweed',\n",
    "        9: 'Shepherds Purse',\n",
    "        10: 'Small-flowered Cranesbill',\n",
    "        11: 'Sugar beet'\n",
    "    }.get(x, 'None')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "794/79450\r"
     ]
    }
   ],
   "source": [
    "CATEGORIES = ['Black-grass', 'Charlock', 'Cleavers', 'Common Chickweed', 'Common wheat', 'Fat Hen', 'Loose Silky-bent',\n",
    "             'Maize', 'Scentless Mayweed', 'Shepherds Purse', 'Small-flowered Cranesbill', 'Sugar beet']\n",
    "\n",
    "scaleSize = 299 #resize figures to 300 px\n",
    "seed = 0        #random seed\n",
    "\n",
    "path='../Seedlings/train/train/*/*.png'\n",
    "files = glob(path)\n",
    "path_test='../Seedlings/test/test/*.png'\n",
    "test_files = glob(path_test)\n",
    "\n",
    "trainImage = []\n",
    "trainLabel = []\n",
    "j = 1\n",
    "num = len(files)\n",
    "\n",
    "for img in files:\n",
    "    if (j >= num):\n",
    "        print(str(j)+\"/\"+str(num), end=\"\\r\")\n",
    "    trainImage.append(cv2.resize(cv2.imread(img), (scaleSize, scaleSize)))\n",
    "    trainLabel.append(img.split('/')[-2])   #Depends on the path of dataset, MODIFY\n",
    "    j = j + 1\n",
    "    \n",
    "trainImage = np.asarray(trainImage)\n",
    "trainLabel = pd.DataFrame(trainLabel)\n",
    "\n",
    "testImage = []\n",
    "testLabel = []\n",
    "j = 1\n",
    "num = len(test_files)\n",
    "\n",
    "for img in test_files:\n",
    "    if (j >= num):\n",
    "        print(str(j)+\"/\"+str(num), end=\"\\r\")\n",
    "    testImage.append(cv2.resize(cv2.imread(img), (scaleSize, scaleSize)))\n",
    "    testLabel.append(img.split('/')[-2])   #Depends on the path of dataset, MODIFY\n",
    "    j = j + 1\n",
    "    \n",
    "testImage = np.asarray(testImage)\n",
    "testLabel = pd.DataFrame(testLabel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(794, 299, 299, 3)\n"
     ]
    }
   ],
   "source": [
    "print(testImage.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "clearTrainImage = []\n",
    "maskTrainImage = []\n",
    "blurredTrainImage = []\n",
    "segmentTrainImage = []\n",
    "sharpTrainImage = []\n",
    "examples = []\n",
    "getEx = True\n",
    "for image in trainImage:\n",
    "    #Gaussian blur\n",
    "    #blurImage = cv2.GaussianBlur(image, (5,5), 0)\n",
    "    \n",
    "    #Convert to HSV\n",
    "    hsvImage = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
    "    \n",
    "    #Create mask\n",
    "    sensitivity = 35\n",
    "    green_lb = (60 - sensitivity, 100, 50) #lower bound of green range\n",
    "    green_ub = (60 + sensitivity, 255, 255) #upper bound of green range\n",
    "    mask = cv2.inRange(hsvImage, green_lb, green_ub)\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (11,11))\n",
    "    mask = cv2.morphologyEx(mask, cv2.MORPH_CLOSE, kernel)\n",
    "    \n",
    "    #segment image\n",
    "    segmentImage = cv2.bitwise_and(image, image, mask = mask)\n",
    "    \n",
    "    #sharpen\n",
    "    blurredImage = cv2.GaussianBlur(segmentImage, (5,5), 0)\n",
    "    sharpImage = cv2.addWeighted(segmentImage, 1.5, blurredImage, -0.5, 0)\n",
    "    maskTrainImage.append(mask)\n",
    "    segmentTrainImage.append(segmentImage)\n",
    "    blurredTrainImage.append(blurredImage)\n",
    "    sharpTrainImage.append(sharpImage)\n",
    "    \n",
    "clearTestImage = []\n",
    "maskTestImage = []\n",
    "blurredTestImage = []\n",
    "segmentTestImage = []\n",
    "sharpTestImage = []\n",
    "examples = []\n",
    "getEx = True\n",
    "for image in testImage:\n",
    "    #Gaussian blur\n",
    "    #blurImage = cv2.GaussianBlur(image, (5,5), 0)\n",
    "    \n",
    "    #Convert to HSV\n",
    "    hsvImage = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
    "    \n",
    "    #Create mask\n",
    "    sensitivity = 35\n",
    "    green_lb = (60 - sensitivity, 100, 50) #lower bound of green range\n",
    "    green_ub = (60 + sensitivity, 255, 255) #upper bound of green range\n",
    "    mask = cv2.inRange(hsvImage, green_lb, green_ub)\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (11,11))\n",
    "    mask = cv2.morphologyEx(mask, cv2.MORPH_CLOSE, kernel)\n",
    "    \n",
    "    #segment image\n",
    "    segmentImage = cv2.bitwise_and(image, image, mask = mask)\n",
    "    \n",
    "    #sharpen\n",
    "    blurredImage = cv2.GaussianBlur(segmentImage, (5,5), 0)\n",
    "    sharpImage = cv2.addWeighted(segmentImage, 1.5, blurredImage, -0.5, 0)\n",
    "    maskTestImage.append(mask)\n",
    "    segmentTestImage.append(segmentImage)\n",
    "    blurredTestImage.append(blurredImage)\n",
    "    sharpTestImage.append(sharpImage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Covert Categories into Label Numbers\n",
    "trainLabels = []\n",
    "for i in range(trainLabel.shape[0]):\n",
    "    trainLabels.append(label_s2n(trainLabel[0][i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from keras import backend as K\n",
    "import os\n",
    "import imp\n",
    "\n",
    "def set_keras_backend(backend):\n",
    "    os.environ['KERAS_BACKEND'] = backend\n",
    "    imp.reload(K)\n",
    "    assert K.backend()==backend\n",
    "    \n",
    "set_keras_backend(\"tensorflow\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "data_generator = ImageDataGenerator(\n",
    "                rotation_range = 180,     #randomly rotate images\n",
    "                zoom_range = 0.1,         #randomly zoom image\n",
    "                width_shift_range = 0.1,  #randomly shift images horizontally\n",
    "                height_shift_range = 0.1, #randomly shift images vertically\n",
    "                horizontal_flip = True,   #randomly flip images horizontally\n",
    "                vertical_flip = True      #randomly flip images vertically\n",
    "            )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications.xception import Xception\n",
    "from keras.callbacks import TensorBoard, ModelCheckpoint\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.regularizers import l2\n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from keras.applications.xception import *\n",
    "\n",
    "from keras.preprocessing import image\n",
    "\n",
    "from keras.utils import np_utils\n",
    "\n",
    "from keras.layers import Dropout, Dense, Input, Activation\n",
    "\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "\n",
    "\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras import optimizers\n",
    "\n",
    "\n",
    "from scipy.misc import imread, imresize\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-62-f84ac5f951a5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0msgd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptimizers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSGD\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.01\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdecay\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-6\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmomentum\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.9\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnesterov\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'AdaDelta'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'categorical_crossentropy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0msharpTrainImage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msharpTrainImage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0mdata_generator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msharpTrainImage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tensorflow/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mcompile\u001b[0;34m(self, optimizer, loss, metrics, loss_weights, sample_weight_mode, weighted_metrics, target_tensors, **kwargs)\u001b[0m\n\u001b[1;32m    602\u001b[0m         \"\"\"\n\u001b[1;32m    603\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 604\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptimizers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    605\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    606\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss_weights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tensorflow/lib/python3.6/site-packages/keras/optimizers.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(identifier)\u001b[0m\n\u001b[1;32m    755\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'tensorflow'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    756\u001b[0m         \u001b[0;31m# Wrap TF optimizer instances\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 757\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midentifier\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    758\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mTFOptimizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midentifier\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    759\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midentifier\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'tf' is not defined"
     ]
    }
   ],
   "source": [
    "batch_size = 16\n",
    "scaleSize=299\n",
    "\n",
    "base_model = Xception(weights='imagenet', input_shape=(scaleSize, scaleSize, 3), include_top=False)\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dropout(0.5)(x)\n",
    "x = Dense(1024, activation='relu')(x)\n",
    "x = Dropout(0.5)(x)\n",
    "predictions = Dense(12, activation='softmax')(x)\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "sgd = optimizers.SGD(lr=0.01,decay=1e-6, momentum=0.9, nesterov=True)\n",
    "\n",
    "model.compile(optimizer='AdaDelta',loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "sharpTrainImage = np.asarray(sharpTrainImage)\n",
    "data_generator.fit(sharpTrainImage)\n",
    "\n",
    "model.fit_generator(data_generator.flow(sharpTrainImage, trainLabels, batch_size=batch_size), steps_per_epoch=len(sharpTrainImage)//batch_size, epochs=100, verbose=1)\n",
    "model.save_weigths('Xception.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
