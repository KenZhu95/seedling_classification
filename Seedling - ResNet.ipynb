{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Seedling - ResNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/py35/lib/python3.5/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import os\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras import optimizers\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D, BatchNormalization\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.applications import *\n",
    "from keras.applications.resnet50 import preprocess_input\n",
    "from sklearn.model_selection import StratifiedShuffleSplit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numbers of sharpTrainImage images 4750\n",
      "Numbers of sharpTestImage images 794\n",
      "Numbers of train labels 4750\n"
     ]
    }
   ],
   "source": [
    "sharpTrainImage = np.load(os.path.join(os.getcwd(),'Image224/sharpTrainImage.npy'))\n",
    "sharpTestImage = np.load(os.path.join(os.getcwd(),'Image224/sharpTestImage.npy'))\n",
    "trainLabels = np.load(os.path.join(os.getcwd(),'Image224/trainLabels.npy'))\n",
    "\n",
    "print(\"Numbers of sharpTrainImage images\", len(sharpTrainImage))\n",
    "print(\"Numbers of sharpTestImage images\", len(sharpTestImage))\n",
    "print(\"Numbers of train labels\", len(trainLabels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(224, 224, 3)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sharpTrainImage[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one - hot coding\n",
    "trainLabels = to_categorical(trainLabels, 12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4750, 12)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainLabels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 3990 for training and 760 for validation\n"
     ]
    }
   ],
   "source": [
    "#x_train, x_valid, y_train, y_valid = train_test_split(x_train, y_train, test_size=0.01, random_state=42)\n",
    "\n",
    "sss = StratifiedShuffleSplit(n_splits=1, test_size=0.16, random_state=42) # Want a balanced split for all the classes\n",
    "\n",
    "for train_index, test_index in sss.split(sharpTrainImage, trainLabels):\n",
    "    print(\"Using {} for training and {} for validation\".format(len(train_index), len(test_index)))\n",
    "    x_train, x_valid = sharpTrainImage[train_index], sharpTrainImage[test_index]\n",
    "    y_train, y_valid = trainLabels[train_index], trainLabels[test_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(\n",
    "                            preprocessing_function = preprocess_input,\n",
    "                            rotation_range=360.,\n",
    "                            width_shift_range=0.3,\n",
    "                            height_shift_range=0.3,\n",
    "                            zoom_range=0.3,\n",
    "                            horizontal_flip=True, \n",
    "                            vertical_flip=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 50\n",
    "learning_rate = 0.0001\n",
    "batch_size = 32\n",
    "dim = 224\n",
    "\n",
    "weights = os.path.join('', 'weights.h5')\n",
    "\n",
    "callbacks = [ EarlyStopping(monitor='val_loss', patience=5, verbose=0), \n",
    "              ModelCheckpoint(weights, monitor='val_loss', save_best_only=True, verbose=0),\n",
    "              ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=2, verbose=0, mode='auto', epsilon=0.0001, cooldown=0, min_lr=0)]\n",
    "\n",
    "base_model = ResNet50(input_shape=(dim, dim, 3), include_top=False, weights='imagenet', pooling='avg') \n",
    "# Average pooling reduces output dimensions\n",
    "x = base_model.output\n",
    "x = Dense(dim, activation='relu')(x)\n",
    "x = Dropout(0.5)(x)\n",
    "predictions = Dense(12, activation='softmax')(x)\n",
    "\n",
    "model = Model(inputs=base_model.input, outputs=predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer=optimizers.Adam(lr=learning_rate), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "125/124 [==============================] - 146s 1s/step - loss: 1.0023 - acc: 0.6827 - val_loss: 0.6818 - val_acc: 0.8026\n",
      "Epoch 2/50\n",
      "125/124 [==============================] - 135s 1s/step - loss: 0.4259 - acc: 0.8674 - val_loss: 0.5797 - val_acc: 0.8303\n",
      "Epoch 3/50\n",
      "125/124 [==============================] - 135s 1s/step - loss: 0.3403 - acc: 0.8893 - val_loss: 0.4927 - val_acc: 0.8566\n",
      "Epoch 4/50\n",
      "125/124 [==============================] - 135s 1s/step - loss: 0.3013 - acc: 0.8988 - val_loss: 0.6062 - val_acc: 0.8184\n",
      "Epoch 5/50\n",
      "125/124 [==============================] - 136s 1s/step - loss: 0.2788 - acc: 0.9004 - val_loss: 0.7158 - val_acc: 0.7868\n",
      "Epoch 6/50\n",
      "125/124 [==============================] - 135s 1s/step - loss: 0.2873 - acc: 0.9002 - val_loss: 0.3920 - val_acc: 0.8645\n",
      "Epoch 7/50\n",
      "125/124 [==============================] - 136s 1s/step - loss: 0.2270 - acc: 0.9208 - val_loss: 0.3349 - val_acc: 0.9066\n",
      "Epoch 8/50\n",
      "125/124 [==============================] - 135s 1s/step - loss: 0.2660 - acc: 0.9158 - val_loss: 0.3305 - val_acc: 0.8934\n",
      "Epoch 9/50\n",
      "125/124 [==============================] - 136s 1s/step - loss: 0.2100 - acc: 0.9251 - val_loss: 0.2894 - val_acc: 0.9132\n",
      "Epoch 10/50\n",
      "125/124 [==============================] - 135s 1s/step - loss: 0.1939 - acc: 0.9318 - val_loss: 0.8379 - val_acc: 0.7474\n",
      "Epoch 11/50\n",
      "125/124 [==============================] - 136s 1s/step - loss: 0.1854 - acc: 0.9289 - val_loss: 0.3758 - val_acc: 0.8750\n",
      "Epoch 12/50\n",
      "125/124 [==============================] - 136s 1s/step - loss: 0.2082 - acc: 0.9250 - val_loss: 0.3126 - val_acc: 0.8974\n",
      "Epoch 13/50\n",
      "125/124 [==============================] - 136s 1s/step - loss: 0.1683 - acc: 0.9405 - val_loss: 0.1283 - val_acc: 0.9526\n",
      "Epoch 14/50\n",
      "125/124 [==============================] - 135s 1s/step - loss: 0.1342 - acc: 0.9538 - val_loss: 0.1783 - val_acc: 0.9289\n",
      "Epoch 15/50\n",
      "125/124 [==============================] - 136s 1s/step - loss: 0.1334 - acc: 0.9530 - val_loss: 0.1401 - val_acc: 0.9474\n",
      "Epoch 16/50\n",
      "125/124 [==============================] - 135s 1s/step - loss: 0.1238 - acc: 0.9589 - val_loss: 0.1411 - val_acc: 0.9474\n",
      "Epoch 17/50\n",
      "125/124 [==============================] - 135s 1s/step - loss: 0.1354 - acc: 0.9528 - val_loss: 0.1411 - val_acc: 0.9474\n",
      "Epoch 18/50\n",
      "125/124 [==============================] - 135s 1s/step - loss: 0.1249 - acc: 0.9562 - val_loss: 0.1331 - val_acc: 0.9513\n",
      "running time:  0:41:50.202134\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "local_start = datetime.datetime.now()\n",
    "# ------ TRAINING ------\n",
    "model.fit_generator(datagen.flow(x_train, y_train, batch_size=batch_size),\n",
    "                    steps_per_epoch=len(x_train)/batch_size, \n",
    "                    validation_data=datagen.flow(x_valid, y_valid, batch_size=batch_size), \n",
    "                    validation_steps=len(x_valid)/batch_size,\n",
    "                    callbacks=callbacks,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1)\n",
    "\n",
    "print('running time: ', datetime.datetime.now()-local_start) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('model_resnet50.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_n2s(x):\n",
    "    return {\n",
    "        0: 'Black-grass',\n",
    "        1: 'Charlock',\n",
    "        2: 'Cleavers',\n",
    "        3: 'Common Chickweed',\n",
    "        4: 'Common wheat', \n",
    "        5: 'Fat Hen',\n",
    "        6: 'Loose Silky-bent',\n",
    "        7: 'Maize',\n",
    "        8: 'Scentless Mayweed',\n",
    "        9: 'Shepherds Purse',\n",
    "        10: 'Small-flowered Cranesbill',\n",
    "        11: 'Sugar beet'\n",
    "    }.get(x, 'None')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Peocess: 0\n"
     ]
    }
   ],
   "source": [
    "predLabel = []\n",
    "for i in range(len(sharpTestImage)):\n",
    "    images = datagen.flow(np.expand_dims(sharpTestImage[i],axis=0))\n",
    "    pred = np.zeros((1,12))\n",
    "    for j,img in enumerate(images):\n",
    "        pred += model.predict(img)\n",
    "        if j > 100:\n",
    "            break\n",
    "    label = np.argmax(pred)\n",
    "    predLabel.append(label_n2s(label))\n",
    "    if (i/100==0):\n",
    "        print(\"Peocess:\",i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "794"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(predLabel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_csv('sample_submission.csv')\n",
    "testName = np.load(os.path.join(os.getcwd(),'Image/testName.npy'))\n",
    "df_test['file'] = testName\n",
    "df_test['species'] = predLabel\n",
    "df_test.to_csv('submission_resnet50.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
